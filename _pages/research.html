---
layout: archive
title: "Secure and Robust Intelligent Sensing Syetems"
permalink: /research/
author_profile: true



---


<p>
<img src="../images/CPS.png" hspace="10" vspace="10" align="left" height="240" width="320" /> <b>Overview:</b> Though the combination of DL models and 3D sensors is viewed as promising in many applications, its vulnerability exposed by OOD samples and cyber-attacks remains unaddressed. Many types of attacks, especially physical attacks, reveal the practicality of injecting malicious inputs through the front-end 3D sensors and lead the back-end DL models to specific wrong outputs.
<br>
This project is supported by NSF under grant <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2347426&HistoricalAwards=false">EER-2347426</a>.


 <br> 
  <b>Slected Publications: </b>
  <br>
  [1]. "Robust roadside physical adversarial attack against deep learning in lidar perception modules", Yang K, Tsai T, Yu H, et al. ACM Asia Conference on Computer and Communications Security, HongKong, 2021.
  <br>
  [2]. "Robust adversarial objects against deep learning models", Tsai T, Yang K, Ho T Y, et al. AAAI Conference on Artificial Intelligence, New York, USA, 2020
</p>

<hr>

<br />
<br />



<h1>Vulnerability Detection in Machine Learning Applications </h1>


<p>
<img src="../images/deployment.png" hspace="10" vspace="10" align="left" height="240" width="320" /> <b>Overview:</b>b> The proliferation of deep learning, especially large language models (LLMs), has marked a paradigm shift today, leading to unprecedented advancements in various downstream tasks. Though deep learning is recognized as a promising solution to plenty of tasks, security concerns also arise regarding its vulnerabilities, such as adversarial examples, backdoor attacks, and jailbreak attacks. The threat of them against systems in real-world applications remains rather unexplored.   
 <br>
This project is supported by NSF under grant <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2419880">CI-2419880</a>.

 <br> 
 <b>Slected Publications: </b>
 <br>


</p>
<hr>

<br />
<br />

<h1>Deep Learning Enhanced Hardware Security </h1>
<p>
<img src="../images/deployment.png" hspace="10" vspace="10" align="left" height="240" width="320" /> <b>Overview:</b>b> The proliferation of deep learning, especially large language models (LLMs), has marked a paradigm shift today, leading to unprecedented advancements in various downstream tasks. Though deep learning is recognized as a promising solution to plenty of tasks, security concerns also arise regarding its vulnerabilities, such as adversarial examples, backdoor attacks, and jailbreak attacks. The threat of them against systems in real-world applications remains rather unexplored.   
 <br>


 <br> 
 <b>Slected Publications: </b>


 <br>


</p>





