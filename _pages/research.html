---
layout: archive
title: "Secure and Robust Intelligent Sensing Syetems"
permalink: /research/
author_profile: true



---


<p>
<img src="../images/CPS.png" hspace="10" vspace="10" align="left" height="240" width="320" /> <b>Overview:</b> Though the combination of DL models and 3D sensors is viewed as promising in many applications, its vulnerability exposed by OOD samples and cyber-attacks remains unaddressed. Many types of attacks, especially physical attacks, reveal the practicality of injecting malicious inputs through the front-end 3D sensors and lead the back-end DL models to specific wrong outputs.
<br>
This project is supported by NSF under grant <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2347426&HistoricalAwards=false">EER-2347426</a>.


 <br> 
  <b>Slected Publications: </b>
  <br>
  [1]. "Robust roadside physical adversarial attack against deep learning in lidar perception modules", Yang K, Tsai T, Yu H, et al. ACM Asia Conference on Computer and Communications Security, HongKong, 2021.
  <br>
  [2]. "Robust adversarial objects against deep learning models", Tsai T, Yang K, Ho T Y, et al. AAAI Conference on Artificial Intelligence, New York, USA, 2020
</p>

<hr>

<br />
<br />



<h1>Vulnerability Detection in Machine Learning Systems </h1>


<p>
Overview:
</p>






